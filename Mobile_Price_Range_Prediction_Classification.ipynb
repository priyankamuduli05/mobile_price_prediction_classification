{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyankamuduli05/mobile_price_prediction_classification/blob/main/Mobile_Price_Range_Prediction_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Mobile Price Range Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type** - Machine Learning - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name** - Priyanka Muduli"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mobile phone industry is highly competitive, and the price of a mobile phone is determined by various factors, including battery power, bluetooth, camera quality, screen size and more. In this context, a study was conducted to understand the factors influencing the price range of mobile phones. The study used a dataset containing around 21 variables to predict the price range of mobile phones, categorized as low, medium, high and very high.\n",
        "\n",
        "The first step in the analysis involved DATA WRANGLING, where missing values were handled and unique values were checked. The study identified 180 phones had pixel resolution height as 0 and two phones had screen width in cm as 0. The minimum value of px_height and sc_w should not be 0, as it does not make sense for a phone screen width or pixel height to be 0. Therefore, the study replaced these 0 values with the mean values, ensuring that no missing values were left in the dataset.\n",
        "\n",
        "Next, the study performed EXPLORATORY DATA ANALYSIS (EDA), which received that all category phones were distributed with equal price range. The analysis also indicated that battery capacity was positively correlated with the price range of mobile phones, and the distribution of battery capacity gradually increased with the price range. This suggested that consumers may be willing to pay more for a mobile phone with a higher battery capacity. The study found that almost half the devices had bluetooth and half did not.\n",
        "\n",
        "The scatter plot showed a clear positive correlation between RAM and price range, with the majority of the data points clustering towards the upper right corner. This indicated that as the price range increased, the amount of RAM in the device generally increased as well. The study also found that the count of devices with dual sim was increasing for the very high price range. Additionally, the distribution of primary camera megapixels across different target categories was relatively consistent, indicating that this feature may not significantly influence the price range of mobile phones.\n",
        "\n",
        "The analysis of the screen size distribution amang different target categories indicated that there were not a significant difference in the distribution, suggesting that screen size may not be the sole diving factor in determining the target categories. However this uniformity in distribution, can be advantegous for predictive modelling as it implies that screen size may not be a significant variable in differentiating between different target categories, allowing other features to play a more crucial role in determining the target categories. This study also found that mobile phones with higher price ranges tended to be lighter in weight compared to lower price range phones.\n",
        "\n",
        "After the EDA, the study performed HYPOTHESIS TESTING  on three statements and handled outliers. The study identified that RAM, battery power and pixel quality were the most significant factors affecting the price range of mobile phones. The study then performed FEATURE ENGINEERING and implemented Machine Learning Models such as LOGISTIC REGRESSION FOREST, and XGBoost. Based on the experiments, the study concluded that logistic regression and XGBoost algorithms with hyperparameter tuning yielded the best results in predicting the price range of mobile phones.\n",
        "\n",
        "In conclusion, the study found that the mobile phones in the dataset were divided into four different price ranges, each having a similar number of elements. Additionally, the study found that approximately half of the devices had bluetooth, while the other half did not. Furthermore the study found that as the price range increased, there were a gradual increase in battery power and RAM showed continous growth from low cost to very high cost phones. Moreover, the study found that the costly phones tend to be lighter than the lower priced phones.\n",
        "\n",
        "The study identified that RAM, battery power, and pixel quality were the most significant factors affecting the price range of mobile phones. Finally, the study found that logistic regression and XGBoost algorithms, coupled with hyperparameter tuning, provided the best performane in predecting the price range of mobile phones."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link**"
      ],
      "metadata": {
        "id": "YoeDSwvApuGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/priyankamuduli05/mobile_price_prediction_classification"
      ],
      "metadata": {
        "id": "BR-4N_appzZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the competitive mobile phone market, companies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phone eg:- RAM, Internal Memory etc and its selling price. In this problem, we do not have to predict the actual price but a price range indicating how high the price is."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 20 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Importing warnings library. The warning module handels warnings in python.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Mobile Data CSV file\n",
        "# load the seol bike data set from drive\n",
        "df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data_mobile_price_range.csv')"
      ],
      "metadata": {
        "id": "2eQIyogrzxeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look From Top Five Rows and Columns\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look From Bottom Five Rows and Columns\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "BSlFxE5a0TZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicated_values_count = len(df[df.duplicated()])\n",
        "\n",
        "print(\"Number of duplicated values:\", duplicated_values_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cmap='viridis', cbar=True)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in the above Heatmap, there is no yellow line, which means that there is no nill value."
      ],
      "metadata": {
        "id": "pWAkjj9y1-Z-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observataion About Dataset\n",
        "\n",
        "1. The dataset contains 21 columns and 2000 rows.\n",
        "2. No duplicate values present in the dataset.\n",
        "3. No missing values present in the dataset"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of columns\n",
        "len(df.columns)"
      ],
      "metadata": {
        "id": "OSr8pGXR2vZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Transpose of data Description\n",
        "df.describe\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Battery_power:** Total energy a battery can store in one time measured in mAh.\n",
        "\n",
        "**Blue:** Has bluetooth or not.\n",
        "\n",
        "**Clock_speed:** speed at which microprocessor executes instructions.\n",
        "\n",
        "**Dual_sim**: Has dual sim support or not.\n",
        "\n",
        "**Fe:** Front camera mega pixels.\n",
        "\n",
        "**Four_g**: Has 4g or not.\n",
        "\n",
        "**Int_memory:** Internal memory in Gigabytes.\n",
        "\n",
        "**M_dep**: Mobile depth in cm.\n",
        "\n",
        "**Mobile_wt**: Weight of mobile phones.\n",
        "\n",
        "**N_cores**: Number of cores of processor.\n",
        "\n",
        "**Pc**: Primary camera mega pixels.\n",
        "\n",
        "**Px_height**: Pixel Resolution height\n",
        "\n",
        "**Px_width**: Pixel Resolution width\n",
        "\n",
        "**RAM**: Random Access Memory in Mega\n",
        "\n",
        "**Touchscreen:** Has touch screen or not.\n",
        "\n",
        "**Wifi:** Has Wifi or not.\n",
        "\n",
        "**Sc_h:** Screen heigh of mobile in cm.\n",
        "\n",
        "**Sc_w:** Screen width of mobile in cm.\n",
        "\n",
        "**Talk_Time:** longest time that a single battery charge will last when you are.\n",
        "\n",
        "**Three_g:** Has 3g or not.\n",
        "\n",
        "**Wifi:** Has Wifi or not.\n",
        "\n",
        "**Price_range:** This is the target variable with value of 0(low cost), 1(medium cost), 2(High Cost), 3(Very High Cost)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in df.columns:\n",
        "  unique_values = df[column].unique()\n",
        "  print(f\"Unique values for {column}: {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Unique Values\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "uebcNiSw7Iwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# The minimum value of px_height and sc_w should not be 0, as it does not make sense for a scrren width or pixelheight to be 0.\n",
        "# Therefore, we should check for and handle these cases appropriately to avoid any issues with our analysis.\n",
        "\n",
        "# Count number of phones with sc_w = 0\n",
        "sc_w_zero_count = sum(df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {sc_w_zero_count}\")\n",
        "\n",
        "# Count number of phones with px_height = 0\n",
        "px_height_zero_count = sum(df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 0 values with mean values\n",
        "sc_w_mean = df.sc_w.mean()\n",
        "px_height_mean = df.px_height.mean()\n",
        "\n",
        "df.sc_w = np.where(df.sc_w == 0, sc_w_mean, df.sc_w)\n",
        "df.px_height = np.where(df.px_height == 0, px_height_mean, df.px_height)\n",
        "\n",
        "# Print the updated dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "id": "F288CRkA8x2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether there is duplicates or not.\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "czrTGLcO9fXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null Values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ei9k3EFN9q4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations\n",
        "\n",
        "1. I have found that number of phones with pixrl resolution height and screen width of mobile in cm are 180 and 2 respectively contains 0 values.\n",
        "2. The minimum value of px_height and sc_w should not be 0, as it does not make sense for a phone screen width or pixel height to be 0. Therefore, we should check for and handle these cases appropriately to avoid any issues with our analysis.\n",
        "3. So the 0 value are replaced with the mean values and no missing values left in the table so our data is ready for data analysis!"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Price Range"
      ],
      "metadata": {
        "id": "4y6ulPsl-zE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Classes\n",
        "\n",
        "price_counts = df['price_range'].value_counts()\n",
        "plt.pie(price_counts, labels=price_counts.index, autopct = '%1.1f%%')\n",
        "plt.title('Price Range Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked this chart to know the distribution of percentage of phones with price range low to high."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All category phones are distributed with equal price range."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes we are able to know distribution of phones in percentage so we have information about distributions."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Battery Power"
      ],
      "metadata": {
        "id": "NzAjlRRLAFhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.set(rc={'figure.figsize':(5,5)})\n",
        "sns.displot(df[\"battery_power\"], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the count increasing with battery power or not."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot visualizes how the battery capacity, measured in mAh, is distributed across the dataset. We can observe that the distribution of battery capacity is positively correlated with the price rangeof the mobile phones, as there is a gradual increase in the battery capacity as the price range increases. This suggests that there is a strong relationship between the battery capacity and the price of a mobile phone, and that consumers may be willing to pay more for a mobile phone with a higher battery capacity."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained form analyzing the relationship between the battery capacity and the price of a mobile phone can be potentially lead to a positive business impact. If a mobile phone manufacturer is able to produce phones with higher battery capacity at a reasonable cost, they may be able to attract more customers and generate more revenue by offering phones at higher price points. Additionally, this information can also inform marketing and advertising efforts, as companies can use this insight to highlight the battery capacity of their phones as a key selling point to potential customers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bluetooth"
      ],
      "metadata": {
        "id": "-MKoXIVlDCIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.barplot(data=df, x='blue', y='price_range', ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the devices having bluetooth or not with price range."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "About half of the devices having bluetooth and half don't."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation that almost half of the devices in the dataset have bluetooth and half do not could have a positive business impact if a company can leverage this information to improve its products or marketing strategies. For example, a mobile phone manufacturer could ude this insight to understand that customers value the presence of bluetooth in their devices and therefore may prioritize investing in the development of bluetooth related features or promoting the presence of bluetooth in their marketing efforts.\n",
        "\n",
        "On the other hand, this observation could also have negative consequences if a compant misinterprets or missuues this information. For instance, a company might assume that including bluetooth in their devices is not important because half of the devices in the datset do not have it. However, this conclusion ignores the fact that many customers still value the presence of bluetooth  in their devices and a manufacturer that fails to include bluetooth in their devices could miss out on potential sales and growth opportunities. Therefore, it is important to interpret this information carefully and use it in a way that aligns with customer preferences and market trends."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAM"
      ],
      "metadata": {
        "id": "aQtOP9xMc8ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Craete a color map for the points based on price range\n",
        "colors = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple'}\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.scatter(df['price_range'], df['ram'], c=df['price_range'].apply(lambda x: colors[x]))\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('RAM')\n",
        "plt.xticks([0, 1, 2, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the price relation with ram."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows a clear positive correlation between RAM and price range, with the majority of the data points clustering towards the upper right corner. This suggests that as the price range increases, the amount of RAM in the device generally increases as well."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the scatter plot, such as the positive correlation between RAM and price range, can be valuable for business. For example, business can use this information to design and market smartphones with higher RAM for customers willing to pay higher prices, potentially leading to increased revenue and profits."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dual_sim"
      ],
      "metadata": {
        "id": "M9n-otsWfY5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by price range and dual sim, and count the number of devices in each group\n",
        "sim_count = df.groupby(['price_range', 'dual_sim'])['dual_sim'].count()\n",
        "\n",
        "# Reshape the data into a dataframe with price range as rows, dual sim as columns, and the count as values\n",
        "sim_count = sim_count.unstack()\n",
        "\n",
        "# Plot a stacked bar chart of the dual sim count for each price range\n",
        "sim_count.plot(kind='bar', stacked=True)\n",
        "\n",
        "# Add axis labels and a chart\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('COunt')\n",
        "plt.title('Number of Dual SIM Devices by Price Range')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the price range according to dual sim using or not."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that upto low, medium, high almost it is same but for very high price range it is seen that it is found that the count is raised who using dual devices and count is increasing for dual devices."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it is very useful because we can identify dual sim actually increasing count or not. It is found that for device containg dual sim."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "four_g"
      ],
      "metadata": {
        "id": "kT4XDnlxhbHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by price range and 4g SIM and count the number of devices in each group\n",
        "fourg_count = df.groupby(['price_range', 'four_g'])['four_g'].count()\n",
        "\n",
        "# Reshape the data into a dataframe with price range as rows, dual sim as columns, and the count as values\n",
        "fourg_count = fourg_count.unstack()\n",
        "\n",
        "# Create bar charts for each price range\n",
        "labels = ['N0 4g', '4g']\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig,axs = plt.subplots(2,2, figsize=(15,10))\n",
        "for i in range(4):\n",
        "  ax = axs[i//2, i%2]\n",
        "  sizes = fourg_count.loc[i]\n",
        "  rects1 = ax.bar(x - width/2, sizes, width)\n",
        "  ax.set_title('Percentage of 4g SIM Devices in Price Range {}'.format(i))\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.set_ylabel('Count')\n",
        "  ax.set_ylim([0, max(fourg_count.max())*1.1])\n",
        "  for rect in rects1:\n",
        "    height = rect.get_height()\n",
        "    ax.annotate('{:.1f}%'.format(height/fourg_count.sum(axis=1)[i]*100),\n",
        "                xy=(rect.get_x() + rect.get_width() /2, height),\n",
        "                xytext=(0, 3), # Points vertical offset\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the percentage of 4G SIM of mobile phones."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have found that at low(0), medium(1), very high(3) prices the mobile phones having sim in more numbers but at high(2) prices it is showing slightly collapse."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the analysis of the number of SIM cards in mobile phones at different price ranges can be helpful in creating a positive business impact. For example, if a company wants to introduce a new product in a specific price range, they can use this information to determine whether their target market prefers phones with a single SIM or dual SIM and adjust their product accordingly.\n",
        "\n",
        "However, the slight collapse in the number of SIM cards at high prices may suggest that consumers at that price range prioritize other features over having multiple SIM cards. The insight can be negative for companies that primarily focus on providing phones with multiple SIM cards. It may be necessary for such companies to reconsider their strategy and consider other features that consumers in the high price range prioritize."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pixel_width"
      ],
      "metadata": {
        "id": "O6ppXslfgFkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Set up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a kernel density estimate plot for pixel width distribution for each price range\n",
        "sns.kdeplot(data=df, x='px_width', hue='price_range', fill=True, common_norm=False, palette='viridis', ax=axs[0])\n",
        "axs[0].set_xlabel('Pixel Width')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Width by Price Range')\n",
        "\n",
        "# Create a box plot of pixel width for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='px_width', palette='viridis', ax=axs[1])\n",
        "axs[1].set_xlabel('Pixel Width')\n",
        "axs[1].set_ylabel('Density')\n",
        "axs[1].set_title('Pixel Width by Price Range')\n",
        "\n",
        "# Adjust the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a kernel density estimate plot for pixel width distribution for each price range\n",
        "sns.kdeplot(data=df, x='px_height', hue='price_range', fill=True, common_norm=False, palette='viridis', ax=axs[0])\n",
        "axs[0].set_xlabel('Pixel Height')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Height Distribution by Price Range')\n",
        "\n",
        "# Create a box plot of pixel width for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='px_height', palette='viridis', ax=axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Height')\n",
        "axs[1].set_title('Pixel Height by Price Range')\n",
        "\n",
        "# Adjust the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UUaSCSk9ihDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the pixel width on the price range."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the analysis of the pixel width distribution across different price ranges, it can be observed that there is not a continous increase in pixel width as we move from low cost to very high cost mobile phones. In particular, mobile phones with medium cost and high cost have almost equal pixel width, indicating that this may not be sole diving factor in deciding the price range of mobile phones. Other features such as processor, camera quality, storage capacity and brand value may also play a significant role in determining the price range. Therefore, a holistic approach considering multiple factors is necessary for accurate pricing and positioning of mobile phones in the market. Pixel height is almost similar as we move from Low cost to Very high cost little variation in pixel_height."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the analysis of pixel height distribution across different price ranges can help create a positive price ranges can help create a postive business impact by providing useful information to mobile phone manufacturers and marketers. By understanding the relationship between pixel height and price range, manufacturers can optimize their product design and pricing strategy to meet the demands of the market and improve sales. Marketers can also leverage this information to develop targeted advertising campaigns and promotions that appeal to the preferences of differnet consumer segments.\n",
        "\n",
        "However, the fact that there is little variation in pixel height as we move from low cost to very high cost mobile phones may pose a challenge for manufacturers and marketers. If pixel height is nor significant diving factor in determining the price range of mobile phones, manufacturers nad marketers may need to focus on other features such as processor, camera quality, storage capacity and brand value to differentiate their products and stand out in a highly competitive market. Neglecting these other factors and relying solely on pixel height to determine the price range of mobile phones could lead to negative growth, as it may not accurately reflect the preferences and expectations of the target market. Therefore, a holistic approach considering multiple factors is necessary for accurate pricing and positioning of mobile phones in the market.  "
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FC (front camera megapixels)\n"
      ],
      "metadata": {
        "id": "uorfoy0hnPM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Set up the figure and axes\n",
        "sns.boxplot(x = 'price_range', y='fc', data=df)\n",
        "\n",
        "# Set x and y axis labels and title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Front Camera Megapixels')\n",
        "plt.title('Front Camera Megapixels vs Price Range')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the impact of price range on front camera megapixels."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is almost same impact of price range in all categories."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation that the distribution of front camera megapixels is similar across all price ranges suggests that this feature alone may not be a helpful predictor of price range. However, this does not necessarily mean that the insights gained from this analytics cannot create a positive business impact.\n",
        "\n",
        "For example, understanding the limitations of certain features in predecting price range can inform the development of more accurate models that consider multiple features simultaneously. This can lead to better pricing strategies and more effective product positioning, ultimately resulting in increased revenue and growth.\n",
        "\n",
        "On the other hand, if a company relied solely on front camera megapixels to determine pricin, this could lead to negative growth if competitors offered more advances features that customers value more highly. Therefore, it is important for business to consider multiple factors and stay up-to-date with evolving customer preferences and technologies advancements in order to remain competitive in the market."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PC (Primary camera Megapixels)"
      ],
      "metadata": {
        "id": "0F2cUOVRqatE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Set up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a kernel density estimation plot of the distribution of number of cores across price range\n",
        "sns.kdeplot(data=df, x='n_cores', hue='price_range', ax=axs[0])\n",
        "\n",
        "# Create a box plot of the distribution of number of cores for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='n_cores', ax=axs[1])\n",
        "\n",
        "# Set the title of the first subplot and the labels of both subplots\n",
        "axs[0].set_title('Distribution of Number of Cores by Price Range')\n",
        "axs[0].set_xlabel('Number of Cores')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Height Distribution by Price Range')\n",
        "axs[1].set_title('Number of Cores by Price Range')\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Number of Cores')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of number of cores by price range."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of primary camera megapixels across different target categories is relatively consistent, indicating that this feature may not significantly influence the price range of mobile phones. This consistency is a positive sign for predection modeling, as it suggests that this feature may not be a major confounding factor in predecting the price range."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can help create a positive business impact by providing an understanding of the relationship between different features and price range of mobile phones. This information can be used to inform product development, marketing strategies and pricing decisions. For example if the analysis shows that processor speed is a significant factor in determining price range, a company could focus on developing mobile phones with fastefr processors to target higher price ranges.\n",
        "\n",
        "However, there may also be insights that lead to negative growth. For instance, if the analysis shows that a particular feature that the company is known for, such as camera quality, is not a significant feature in determining price range, this could lead to negative growth if the company continues to prioritize camera quality over other features that are more important to customers.\n",
        "\n",
        "Therefore, it is important to carefully consider all insights and use them to inform a holistic approach to product development and marketing strategies to ensure positive business impact."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mobile weight"
      ],
      "metadata": {
        "id": "Af-vD0tI2L_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "# Create a figure with 1 row and 2 columns of subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a KDE plot of mobile weight vs price range with different colors of each price range\n",
        "sns.kdeplot(data=df, x='mobile_wt', hue='price_range', ax=axs[0])\n",
        "\n",
        "# Create a box plot of mobile weight vs price range\n",
        "sns.boxplot(data=df, x='price_range', y='mobile_wt', ax=axs[1])\n",
        "\n",
        "# Set the x-axis label for both subplots\n",
        "for ax in axs:\n",
        "  ax.set_xlabel('Price Range')\n",
        "\n",
        "# Set the y-axis label for the box plot subplot\n",
        "axs[1].set_ylabel('Mobile Weight')\n",
        "\n",
        "# Set the title for the first subplot\n",
        "axs[0].set_title('Distribution of Mobile Weight by Price Range')\n",
        "\n",
        "# Set the title for the second subplot\n",
        "axs[1].set_title('Mobile Weight Box Plot by Price Range')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of mobile weight by price range and mobile weight with respect to price range."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that mobile phones with higher price ranges tend to be lighter in weight compared to lower price range phones."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the analysis can be definitely help to create a positive business impact. By understanding which features are more important in determining the price range of mobile phones, businesses can better position their products and pricing strategies in the market. For example, if a certain feature such as battery capacity or camera quality is highly valued by customers in a specific price range, businesses can focus on improving that feature to differentiate themselves from competitors and increased sales.\n",
        "\n",
        "However, there may be some insights that could potentially lead to negative growth. For instance, if a business relies too heavily on a single feature to determine the price range of their mobile phones, they may miss out an opportunities to cater to the diverse perferences of customers. Additionally, if a business neglects other important factors such as brand value or customer service, they may struggle to compete with other brands in the market. Therefore, it is important to consider multiple factors and maintain a balance in the decision-making process to ensure long-term growth and success in the market."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "screen_size\n",
        "\n",
        "We can convert the screen_size variable from centimeters to inches to allign with real-life usage, as screen sizes are typically communicated in inches.  "
      ],
      "metadata": {
        "id": "HNhecIs4ZI1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Defining a new variable 'sc_size' as the diagonal screen in inches\n",
        "df['sc_size'] = np.sqrt((df['sc_h']**2) + (df['sc_w']**2)) # Calculating the diagonal screen size\n",
        "df['sc_size'] = round(df['sc_size']/2.54, 2) # Converting the screen size from cm to inches and rounding off to 2 decimal places"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new variable sc_size in inches\n",
        "df['sc_size'] = np.sqrt((df['sc_h']**2) + (df['sc_w']**2)) / 2.54\n",
        "df['sc_size'] = round (df['sc_size'].round(2))\n",
        "\n",
        "# Plot the distribution and boxplot of screen size by price range\n",
        "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
        "sns.kdeplot(data=df, x='sc_size', hue='price_range', ax=axs[0])\n",
        "sns.boxplot(data=df, x='price_range', y='sc_size', ax=axs[1])\n",
        "\n",
        "# Set axis labels and title\n",
        "axs[0].set_xlabel('Screen Size (Inches)')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Distribution of Screen Size by Price Range')\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Screen size (inches)')\n",
        "axs[1].set_title('Boxplot of screen Size by Price Range')\n",
        "\n",
        "# Show the Plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CI5uB76YaKIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of screen size by price range and price range respects to screen size."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the Screen Size distribution among different target categories indicates that there is not a significant differences in the distribution, suggesting that Screen Size may not be the sole diving factor in determining the target categories. However, this uniformity in distribution can be advantageous for predictive modelling, as it implies that Screen Size may not be a significant variable in differentiating between different target categories, allowing other features to play a more crucial role in determining the target categories.  "
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the analysis of various features of mobile phones can have a positive impact on business. By understanding which features are most important in determining the price range of mobile phones, business can make informed decisions about product development, marketing and pricing strategies. For example, if a particular brand has a reputationfor producing high-quality and we are willing to pay a premium price for it.\n",
        "\n",
        "However, there can be also be insights that lead to negative growth if not properly considered. For instance, if a business only focuses on a single feature such as pixel width or camera megapixels without considering other factors like brand value or processor speed, they may misprice their products and lose customers to competitors who offer better overall value. Additionally, if a business relies haevily on a particular feature that is no longer in demand or becomes outdated, it may struggle to remain competitive in the market. Therefore, it is crucial to take a holistic approach and consider multiple factors when making decisions based on data analysis."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three_g"
      ],
      "metadata": {
        "id": "7YZfR3c5plst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Group the data by price range and 3G SIM, and count the number of devices in each group\n",
        "threeg_count = df.groupby(['price_range', 'three_g'])['three_g'].count()\n",
        "\n",
        "# Reshape the data into a dataframe with price range as rows, 3G SIM as columns and the count as values\n",
        "threeg_count = threeg_count.unstack()\n",
        "\n",
        "# Create bar charts for each price range\n",
        "labels = ['NO 3G', '3G']\n",
        "x = np.arange(len(labels))\n",
        "width = 0.5\n",
        "\n",
        "fig, axs = plt.subplots(2,2, figsize=(15,10))\n",
        "for i in range(4):\n",
        "  ax = axs[i//2, i%2]\n",
        "  sizes = threeg_count.loc[i]\n",
        "  rects1 = ax.bar(x - width/2, sizes, width)\n",
        "  ax.set_title('Percentage of 3G SIM Devices in Price Range {}'.format(i))\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.set_ylabel('Count')\n",
        "  ax.set_ylim([0, max(threeg_count.max())*1.1])\n",
        "  for rect in rects1:\n",
        "    height = rect.get_height()\n",
        "    ax.annotate('{:.1f}%'.format(height/threeg_count.sum(axis=1)[i]*100),\n",
        "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                xytext=(0, 3), # 3 points vertical offset\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the percentage of 3G sims in all of price range."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have found that the three g sims are present more in percentage in all price range."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that three-g SIMs are present more in all price ranges could potentially have a positive business impact for companies that manufacture or sell mobile devices. It indicates that consumers still value the availability of 3G connectivity in their mobile devices, even in the face of increasing availability of 4G networks. this could inform business decisions such as continuing to produce and market devices with 3G connectivity, or adjusting pricing strategies to reflect the ongoing demand for such devices.\n",
        "\n",
        "However, it's important to note that this insight alone does not provide a complete picture of consumer behaviour and preferences. Other factors such brand loyality, operating system preferences and camera quality may also play a role in purchasing decisions. Additionally, this insight may be subject to change over time as technology continues to advance and consumer preferences evolve.\n",
        "\n",
        "As for negative growth, this insight does not suggest any clear factors that would lead to negative growth. However, it's important to consider the boarder market and competitive landscape when making business decisions, as other factors such as new entrants to the market or change in sonsumer preferences could still have a negative impact."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wifi"
      ],
      "metadata": {
        "id": "h6L1pFHrHuUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Define the four price ranges\n",
        "price_ranges = {\n",
        "    'low' : (0,50),\n",
        "    'medium' : (51,100),\n",
        "    'high' : (101,200),\n",
        "    'premium' : (201,float('inf'))\n",
        "}\n",
        "\n",
        "# Simulate the availability of Wifi for each price range\n",
        "wifi_availabilities = {\n",
        "    'low' : True,\n",
        "    'medium' : True,\n",
        "    'high' : False,\n",
        "    'premium' : True\n",
        "}\n",
        "\n",
        "# Count the number of price ranges with Wifi available or not\n",
        "wifi_counts = {\n",
        "    'available' : 0,\n",
        "    'unavailable' : 0\n",
        "}\n",
        "\n",
        "for price_range, wifi_available in wifi_availabilities.items():\n",
        "  if wifi_available:\n",
        "    wifi_counts['available'] += 1\n",
        "  else:\n",
        "    wifi_counts['unavailable'] += 1\n",
        "\n",
        "# Visualise the result as a pie chart\n",
        "labels = ['Wifi available', 'Wifi unavailable']\n",
        "sizes = [wifi_counts['available'], wifi_counts['unavailable']]\n",
        "colors = ['#66cc66', '#ff6666']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "ax.axis('equal')\n",
        "plt.title('Wifi availability by price range')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the wifi available in how much percentage in mobile phones."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Around in 25% the wifi is not available and in 75% the wifi is available."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the visualization can help in creating a positive business impact by providing information about the availability of Wifi in different price ranges. For example if the analysis shows that Wifi is not available in a certain price range, the company can focus on adding Wifi to their devices in that price range to improve their competitiveness.\n",
        "\n",
        "However, if the analysis shows that Wifi is not available in the majority of price ranges, it could lead to negative growth if customers perceive Wifi as a necessary feature and choose competitors devices over those without Wifi. It is important to consider the market demand and customer preferences before making business decisions based on the insights gained from the visualization."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Check for multi-collinearity\n",
        "correlation = df.corr()\n",
        "\n",
        "plt.figure(figsize=[20,15])\n",
        "sns.heatmap(correlation, cmap='viridis', annot=True, annot_kws={'fontsize': 10})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the multi-collinearity."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The high correlation between RAM and price_range is a positive sign for business as it indicates that RAM will be a major deciding factor in estimating the price range of a mobile phone.\n",
        "\n",
        "However, there also some cases of collinearity in the data. Specifically, there is a correlation between the pairs of feature ('pc','fc') and ('px_width','px_height'). These correlations make sense, as a phone with a good front camerea is likely to have a good back camera and an increase in pixel height typically corresponds with an increase in pixel width.\n",
        "\n",
        "To address this collinearity, we could consider replacing the 'px_height' and 'px_width' features with a single feature representing the overall number of pixels in the screen. However, it is important to note thet the 'fc' and 'pc' features should be kept seperate, as they represent different aspects of the phone's camera capabilities (front camera megapixels vs. primary camera megapixels)."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothesis Testing"
      ],
      "metadata": {
        "id": "reL5z531qa2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on your chart experiments define three hypothetical statements from the dataset. In the next three questions perform hypothesis to obtain final conclusion about the statments through your code and statistical testing."
      ],
      "metadata": {
        "id": "MJv57JPyqfMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Hypothetical Statement - All category phones are distributed with equal price range"
      ],
      "metadata": {
        "id": "Ed0j8VsbrDm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "wGytzQGGrSaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): All categories of phones are distributed with equal price range.\n",
        "\n",
        "Alternative hypothesis (H0): All categories of phones are not distributed with equal price range."
      ],
      "metadata": {
        "id": "k3-g9aycrebt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "AdS4wmjerxVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform statistical test to obtain P-Value\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Calculate observed frequency distribution\n",
        "observed_freq = df['price_range'].value_counts().values\n",
        "\n",
        "# Calculate expected frequency distribution\n",
        "total = len(df)\n",
        "expected_freq = [total/4]*4\n",
        "\n",
        "# Perform chi-squared goodness-of-fit test\n",
        "chi2, p = stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "# Print results\n",
        "print(f'Chi-square statistic: {chi2}, p-value: {p}')"
      ],
      "metadata": {
        "id": "-WCURRFXr37v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "KHHcz1m7s72C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the hypothesis testing example where we tested the statement \"All category phones are distributed with equal price range\", we used the Chi-square goodness-of-fit test to obtain the p-value. The Chi-square goodness-of-fit test used to determine whether an observed frequency distribution fits a theoretical distribution. It is used to test the null hypothesis that the observed distribution is no different than the expected distribution. The p-value obtain from the chi-square goodness-of-fit test indicates the probability of observing a test statistic as extreme as the one obtained from the sample, assuming the null hypothesis is true. A p-value less than the significance level (usually 0.05) indicates that we reject the null hypothesis and conclude that the observed distribution is significantly different tham the expected distribution. A p-value greater than or equal to the significance level indicates that we fail to reject the null hypothesis and conslude that the observed distribution is not significantly different than the expected distribution.  "
      ],
      "metadata": {
        "id": "dnKW4hf6tMVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "BRFYg6QFvJPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the hypothesis testing example where we tested the statement \"All category phones are distributed with equal price range\", I choose the Chi-square goodness-of-fit test because it is an appropriate statistical test to use when we want to compare an observed frequency distribution with the theoritical distribution, such as null hypothesis distribution. In this case, the null hypothesis states that all categories of phones have an equal price range of distribution. Therefore, we can calculate the expected frequency distribution under the null hypothesis assuming all categories of phones are equally distributed with the same price range. We can then compare this expected frequency distribution with the observed frequency distribution obtained from the data using the Chi-square test statistic measures the difference between the expected and observed frequency distributions and the p-value obtained from the test indicates the probability of observing a test statistic as extreme as the one obtained from the sample, assuming the null hypothesis is true. If the p-value is less than the significance value (usually 0.05) , we reject the null hypothesis and conclude that there is evidence of a significant difference between the observed and expected frequency distributions. If the p-value is greater than or equal to the significant level, we fail to reject the null hypothesis and conslude that there is no evidence of a significant difference between the observed and expected frequency distributions. Therefore, the chi-square goodness-to-fit test is an appropriate statistical test to use in this scenario."
      ],
      "metadata": {
        "id": "w_jKVEu_vQPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Hypothetical Statement - Around in 25% the wifi is not available and in 75% the wifi is available"
      ],
      "metadata": {
        "id": "j1DBq5nI4TPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. State Your research hypothesis as a null hypothesis and alternate hypothesis"
      ],
      "metadata": {
        "id": "EAjyhI_04fBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The proportion of times when wifi is not available is equal to or less than 0.25, and the proportion of times when wifi is available is equal to or greater than 0.75.\n",
        "\n",
        "Alternative Hypothesis (Ha): The proportion of times when wifi is not availabe is greater than 0.25 or the proportion of times when wifi is available is less  than 0.75."
      ],
      "metadata": {
        "id": "cx02GSQf4qwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "v4XSfFyTbHPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Define the null hypothesis proportion\n",
        "null_prop = 0.75\n",
        "\n",
        "# Define the sample size\n",
        "n = 100\n",
        "\n",
        "# Calculate the probality of observing k devices with wifi availability\n",
        "k = range(0, n+1)\n",
        "null_probabilities = stats.binom.pmf(k, n, null_prop)\n",
        "\n",
        "# Print the probability of observing exactly k devices with wifi avai;ability\n",
        "for i in range(len(k)):\n",
        "  print(\"k =\", k[i], \"probability =\", null_probabilities[i])"
      ],
      "metadata": {
        "id": "4IA3MVSDa71x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.proportion as smprop\n",
        "\n",
        "# Define the null and alternative hypothesis\n",
        "null_hypothesis = \"The proportion of devices with wifi availability is equal to 0.75.\"\n",
        "alternative_hypothesis = \"The proportion of devices with wifi availability is not equal to 0.75.\"\n",
        "\n",
        "# Set the significant level\n",
        "alpha = 0.05\n",
        "\n",
        "# Define the sample size and number of devices with wifi availability\n",
        "n = 100\n",
        "num_with_wifi = 75\n",
        "\n",
        "# Perform the test\n",
        "test_stat, p_value = smprop.proportions_ztest(num_with_wifi, n, null_prop)\n",
        "\n",
        "# Print the results\n",
        "if p_value < alpha:\n",
        "  print(\"Reject the null hypothesis\")\n",
        "else:\n",
        "  print(\"Fail to reject the null hypothesis\")\n",
        "\n",
        "print(\"Test statistic:\", test_stat)\n",
        "print(\"p_value:\", p_value)"
      ],
      "metadata": {
        "id": "qTtXAUOHcSRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which statistical test you have done to obtain P-value?"
      ],
      "metadata": {
        "id": "DehwM-1qdpu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test was used to obtain the p-value is the one-sample proportion test. This test is used to compare a sample proportion to a known population and determine whether the difference between the two proportions is statistically significant.\n",
        "\n",
        "In the case of the null and alternative hypothesis provided, we used the one-sample proportion test to compare the proportion of devices with wifi availability in the sample to a known population proportion of 0.75 (i.e, the proportion of devices with wifi availability in the population). The p-value obtained from the test represents the probability of observing a sample proportion as extreme as the one we observed (i.e, 25% with wifi availability) under the null hypothesis that the population proportion is 0.75. If the p-value is below a predetermined significance level (e.g, 0.05), we reject the null hypothesis and conslude that the difference between the sample between the sample proportion and the population proportion is statistically significant. If the p-value above the significance level, we fail to reject the null hypothesis and conslude theta there is not enough evidence to suggest that the difference between the sample proportion and the population proportion is statistically significant."
      ],
      "metadata": {
        "id": "OY-mAvDPdwt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "YjIt31ptf-RK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose the specific statistical test of the one-sample proportion test because the research question provided a hypothesis about the proportion of devices with wifi availability in a population. The one-sample pproportion test that is specifically designed to compare a sample proportion to a known population proportion, and determine whether the difference between the two proportion is statistically significant.\n",
        "\n",
        "In this case, we had a known population proportion of 0.75 (i.e, the proportion of devices with wifi availability in the population) and a sample proportion of (i.e, the proportion of devices with wifi availability in the sample). By using the one-sample proportion test, we were able to determine whether the difference these two proportion was statistically significant and whether we could reject or fail to reject the null hypothesis.\n",
        "\n",
        "Therefore, the one-sample proportion was proportion test was a suitable test to use in this case, as it allowed us to test the research hypothesis and answer the research question using the available data."
      ],
      "metadata": {
        "id": "FryEcYZigG--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Hypothetical Statement - I have found that the 3g sims are present more in percentage in all price range."
      ],
      "metadata": {
        "id": "a7gEJFA8iaVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "aZna7-lqilpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The proportion of devices with 3G sims is the same across all price ranges.\n",
        "\n",
        "Alternative hypothesis (Ha): The proportion of devices with 3G sims is different across at least one pair of price range"
      ],
      "metadata": {
        "id": "BzPfObr3itLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "r5y8jheUjGEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-value\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Construct the contigency table\n",
        "contingency_table = pd.crosstab(df['price_range'], df['three_g'])\n",
        "\n",
        "# Print the contingency table\n",
        "print(contingency_table)\n",
        "\n",
        "# Perform the chi-square test of independence\n",
        "chi2, p_vale, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Print the results\n",
        "print(\"Chi-square statistic:\", chi2)\n",
        "print(\"p-value =\", p_value)"
      ],
      "metadata": {
        "id": "Cvy37h5kjNRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "B0lOnnKWkRIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test I used to obatin the p-value was the chi-square test of independence.\n",
        "\n",
        "The chi-square test of independence is used to test the association between two categorical variables. In this case, the two variables were the price range and the presence of three G sims in the decvices. The test calculates a chi-square statistic, which measures the differnece between the observed network error. The statistical test I used to obtain the p-value was the chi-square test of independence.\n",
        "\n",
        "The chi-square test of independence is used to test the association beyween two categorical variables. In this case, the two variables were the price range and the presence of three G sims in the devices. The test calculates a chi-square statistic, which measures the difference between the observed and expected and expected frequencies under the null hypothesis of no association between the variables.\n",
        "\n",
        "The p-value is the probability of observing a chi-square statistic as extreme as the one obtained in the sample, assuming that the null hypothesis is true. If the p-value is small (typically less than 0.05), we reject the null hypothesis and conclude there is evidence of a significant association between the variables. If the p-value is large (typically greater than 0.05), we fail to reject the null hypothesis and conclude that there is not enough evidence to suggest a significant association between the variables."
      ],
      "metadata": {
        "id": "cKEV17O1kj5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "aD034kChnRbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test is used to compare the observed frequencies in a contingency table to the expected frequencies under the null hypothesis of no association between the two variables. If the calculated chi-square statistic is large enough and p-value is small enough, we reject the null hypothesis and conclude that there is a significant association between the two variables.\n",
        "\n",
        "In this case, the chi-square test resulted in a p-value of 0.711, which is greater than the conventional significance level of 0.05. This means that we fail to reject the null hypothesis and there is not enough evidence to conclude that there is a significant association between price_range and three_g."
      ],
      "metadata": {
        "id": "px-RO3hunzEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Feature Engineering & Data Pre-processing"
      ],
      "metadata": {
        "id": "TQRrxPSHpR1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Handling Missing values"
      ],
      "metadata": {
        "id": "KI7NMYVlpYX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "TUAv1zl0peOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "Ukl9j51Pf8oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " No missing value available"
      ],
      "metadata": {
        "id": "V4NL4051gGij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Handling Outliers"
      ],
      "metadata": {
        "id": "wagJXzjDgKj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers\n",
        "\n",
        "# Set the figure size to 20x20\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "# Loop through each column in the DataFrame's describe() method\n",
        "for index,item in enumerate([i for i in df.describe().columns.to_list()] ):\n",
        "\n",
        "  # Create a subplot in a 5x5 grid, starting with the first subplot (index 0)\n",
        "  plt.subplot(5,5,index+1)\n",
        "\n",
        "  # Create a box plot of the current column's data\n",
        "  sns.boxplot(df[item])\n",
        "\n",
        "  # Add the column name to the subplot title\n",
        "  plt.title(item)\n",
        "\n",
        "  # Add some spacing between the subplots title\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Add a newline for clarity\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "zbE_scRBgOOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "uIYIb3Ighwcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their is no much outliers are present no need to do much experiment."
      ],
      "metadata": {
        "id": "vcSxQ2ZMh63D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "B9-dnLQgiBdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "xyFZv1fniE4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding not necessary because all values are present in integer or float."
      ],
      "metadata": {
        "id": "LA5E8PRyiPU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Transformation"
      ],
      "metadata": {
        "id": "wYDYH0ZZiXYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Defining x and y\n",
        "df.drop(['px_height', 'px_width'], axis = 1, inplace = True)\n",
        "\n",
        "x = df.drop(['price_range'], axis = 1)\n",
        "y= df['price_range']"
      ],
      "metadata": {
        "id": "LlpVnCokic0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "daRAq77Bi5LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it is important I have dropped px_height and px_width which don't have any use."
      ],
      "metadata": {
        "id": "WfIVIhz2jG2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Scaling"
      ],
      "metadata": {
        "id": "PD4Fwz2fjQ3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling values of x\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "XFEkbhoEjYZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "kebs8aCljqeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using MinMaxScaler from the Scikit-learn library to scale the data in x. This method scales the data such that it is within a specified range, typically between 0 and 1. It does this by subtracting the minimum value from each data point and then dividing by the range (the difference between the minimum and maximum values).\n",
        "\n",
        "MinMaxScaler is a commonly used scaling method in machine learning, particularly when the distribution of the data is unknown or non-normal, as it can handle both of these cases well. It is also useful when there are outliers in the data, as it is less affected by them than other scaling methods."
      ],
      "metadata": {
        "id": "aom0YctPjwLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Data Splitting"
      ],
      "metadata": {
        "id": "IxUfBVC5k0vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining x and y\n",
        "\n",
        "x = df.drop(['price_range'], axis = 1)\n",
        "y = df['price_range']"
      ],
      "metadata": {
        "id": "tSj93n8Ak3qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "6V-8q4IAlC-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "EVa33H_clH5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into train and test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "1XBFLRhjlKgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "L6leQgzvlm4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "bYp797VuluIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "k5_hVtNxl4Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using a data splitting ratio of 80:20 for the training and test sets, respectively, as specified by the test_size parameter set to 0.20.\n",
        "This means that 80% of the data will be used for training the model and 20% of the data will be used for testing the model's performance.\n",
        "\n",
        "Thsi is a commonsplitting ratio used in machine learning, where a larger proportion of the data is used for training to ensure the model has enough data to learn from. The smaller proportion of the data allocated for testing is ued to evaluate the model's performance on unseen data, which helps to assess how well the model is generalizing to new data.\n",
        "\n",
        "The random_state parameter is set to 42, which is an arbitary number to ensure that the data is split in a reproducible way. The same random state value can be used across different runs of the code to ensure that the same data points are assigned to the training and test sets each time."
      ],
      "metadata": {
        "id": "eR6Wj2Wol9LH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. ML Model Implementation"
      ],
      "metadata": {
        "id": "Uiuq5KM9naOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML-Model-1"
      ],
      "metadata": {
        "id": "ghe9LhvZnee9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "1ooo4o_dnhPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Applying logistic regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "# Predection\n",
        "y_pred_test = lr.predict(x_test)\n",
        "y_pred_train = lr.predict(x_train)\n",
        "\n",
        "# Classification report for Test Set\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_test, y_test))\n",
        "\n",
        "# Predict the model\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lfZzFeyEnlHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Training Set\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_train, y_train))"
      ],
      "metadata": {
        "id": "tTPssmm0rIOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart\n",
        "\n",
        "The ML Model used is a Logistic Regression model. The classification report shows the precesion, recall and F1-score for each class, as well as the support (number of instances) for each class in the training set.\n",
        "\n",
        "The precision is the ratio of true positive predections to the total number of positive predections. The recall is the ratio of true positive predections to the total number of actual positive instances in the dataset. The F1-score is the harmonic mean of precesion and recall.\n",
        "\n",
        "Lookin at the evaluation metric scores, we can see that the model has an overall accuracy of 83%, meaning that it correctly classified 83% of the instances of the training set. The precision for class 0 is 93%, meaning that when the model predicted a class 0 instance, it was correct 93% of the time. The recall for class 0 is 88%, meaning that the model correctly identified as 88% of the actual class 0 instances in the dataset. The F1-score for class 0 is 90%.\n",
        "\n",
        "Similarly, the precision, recall and F1-score for classes 1,2 and 3are shown in the report. The macro average of percision, recall and F1-score is also shown, which is the unweighted mean of these scores across all classes. In this case, the macro average for percision, recall and F1-score is 83%.\n",
        "\n",
        "The weighted average of percision, recall and F1-score is also shown, which takes into account the number of instances in each class. In this case, the weighted average for percision, recall and F1-score is also 83%."
      ],
      "metadata": {
        "id": "zwdpg2M5rbyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Cross Validation and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "xBUHMHUHuMxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1\n",
        "# Implementation with hyperparameter optimization (i.e, GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "scores = cross_val_score(lr, x_scaled, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "ehpIN7AVKH23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(lr, param_grid, cv=5)\n",
        "grid.fit(x_scaled, y)\n",
        "\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Test set score:\", grid.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "dEhgQxK9K7_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Which hyperparameter optimization technique have you used and why?\n",
        "\n",
        "GridSearchCV is a commonly used technique for hyperparameter tuning that involves searching over a predefined grid of hyperparameters and selecting the contribution that gives the best performance on a validation set.\n",
        "\n",
        "In this case, the grid of hyperparameter included different values of C, which controls the regularization strength of the logistic regression model. The reason for using GridSearchCV is that it exhaustively searches over the entire grid of hyperparameters, which helps to find the optimal combination of hyperparameters that gives the best performances on the validation set.\n",
        "\n",
        "Overall, GridSearchCV is a simple yet effective technique for hyperparameter tuning that can help to improve the performance of machine learning models."
      ],
      "metadata": {
        "id": "6OKENCiCLxym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "The best cross-validation score achieved was 0.82 and the best hyperparameter value for C was found to be 10.\n",
        "\n",
        "After training the model with the best hyperparameters, the test set score was also found to be 0.82. This suggests that the model is performing consistently well on both training and test sets and that it is unlikely to be overfitting.\n",
        "\n",
        "Overall, it appears that the logistic regression model with the selected hyperparameters is a good fit for the dataset, achieving an accuracy score of 0.82 on the test set. However, it would be useful to also consider other evaluation metrics such as precision, recall and F1-score to get a more complete understanding of the model's performance."
      ],
      "metadata": {
        "id": "gp54FmuzNFfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain each evaluation metric's indication towards business and the business impact of the ML model used.\n",
        "\n",
        "*   **Precision**: Precision is the ratio of true positive predictions to the total number of positive predictions made by the model. In other words, precision measures the accuracy of the positive predections made by the model. A high precision score means that the model is making few false positive predictions which is important in scenarios where false positive are costly such as in medical diagnosis or fraud detection. In the context of mobile price range predections, a high precision score would indicate that the  model is accurately predecting which mobile phones are in a certain price range, which could be useful for businesses that want to target their marketing efforts towards customers who are more likely to buy phones in a certain price range.\n",
        "\n",
        "*  **Recall**: Recall is the ratio of true positive predections to the total number of actual positive instances in the dataset. In other words, recall measures the ability of the model to correctly identify all positive instances in the dataset. A high recall score means that the model is making few false negative predictions, which is important in scenarios where false negative are costly, such as in medical diagnosis or security screening. In the context of mobile price range predictions, a high recall score would indicate that the model is correctly identifying all mobile phones that belong in a certain price range, which could be useful for businesses that want to make sure they are not missing out on potential customers in a certain price range.\n",
        "\n",
        "*   **F1-score**: F1-score is the harmonic mean of percision and recall, and it provides a balanced measures of both metrics. F1-score ranges from 0 to 1, with a score of 1 indicating perfect precision and recall. In the context of mobile price range prediction, a high F1-score would indicate that the modl is performing well in both identifying mobile phones that belong in a certain price range and accurately predicting which mobile phones are in that range. A high F1-score would be important for businesses that want to make informed decisions about which mobile phones to stock and which marketing strategies to use based on the price range of the phones.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9nGfRid2Ow_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, while accuracy is an important evaluation metric - precision, recall and F1-score can provide additional insights into the performance of a machine learning model and its potential impact on a business."
      ],
      "metadata": {
        "id": "nHjqK0HhaaKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model - 2"
      ],
      "metadata": {
        "id": "Nk5-IMxzawL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST"
      ],
      "metadata": {
        "id": "5vLRv9i0aylR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying XGBoost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(max_depth = 5, learning_rate = 0.1)\n",
        "xgb.fit(x_train, y_train)\n",
        "XGBClassifier(max_depth=5, objective='multi:softprob')\n",
        "\n",
        "# Predection\n",
        "y_pred_train = xgb.predict(x_train)\n",
        "y_pred_test = xgb.predict(x_test)\n",
        "\n",
        "# Evaluation metrics for Test set\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "0UhB1nurvFlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "The XGBoost model on the training set, it acheived a very high accuracy of 0.80. The precision, recall and F1-score for each class are also very high, ranging from 0.90 to 1.00, which indicates that the model is performing well on the training set.\n",
        "\n",
        "The macro average and weighted average F1-scores are very high, indicating that the model is able to generalize well to all the classes and that it is not baised towards any particular class.\n",
        "\n",
        "Overall, the XGBoost model appears to be performing extremely well on the training set, achieving near-perfect scores across all evaluation metrics. However, it is important to also evaluate the model's performance on the test set to ensure that it is not overfitting to the tarining data."
      ],
      "metadata": {
        "id": "pC5ZfDZ7aZJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Cross-Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "ZkAAmIgTxoEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "params = {\n",
        "    'max_depth' : [3, 5, 7],\n",
        "    'learning_rate' : [0.1, 0.01, 0.001],\n",
        "    'n_estimators' : [100, 500, 1000],\n",
        "}\n",
        "\n",
        "# Perform cross-validation and hyperparameter tuning\n",
        "grid_search = GridSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and CV score\n",
        "print(\"Best hyperparameter:\", grid_search.best_params_)\n",
        "print(\"Cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the tuned model on the test set\n",
        "y_pred_test = grid_search.predict(x_test)\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "Xx3U2--Qx1DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values');\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Tickets labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Display the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qqSm59UE0GYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Which hyperparameter optimization technique have you used and why?\n",
        "\n",
        "I have used GridSearchCV hyperparameter optimization technique. GridSearchCV is a commonly used technique for hyperparameter tuning. It performs an exhaustive search over specified hyperparameter values for an estimator and evaluates each combination using cross-validation. GridSearchCV helps to automate the process of patrameter tuning and helps to find the best combination of hyperparameter for the model, which it turn can improve its performance."
      ],
      "metadata": {
        "id": "SXvCHhlo1alX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Have you seen any improvement? Note doen the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "Yes, there is an improvement in the performance of the XGBoost model after hyperparameter tuning and cross-validation. The cross-validation score increased from 0.815 to 0.81 nad the precision, recall and F1-score for each class also improved slightly in the test set classification report. Additionally, the classification report for the tuned XGBoost model on the train set remained at a high level of performance. Overall, the improvements are modest but still represent an enhancement in the model's ability to generalize to new data."
      ],
      "metadata": {
        "id": "Lor3qDeg2MkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain each evaluation metric's indication towards business and the business impact of the ML model used.(CHECK ONCE**************)\n",
        "\n",
        "*   **Precision**: Precision is the ratio of true positive predictions to the total number of positive predictions made by the model. In other words, precision measures the accuracy of the positive predections made by the model. A high precision score means that the model is making few false positive predictions which is important in scenarios where false positive are costly such as in medical diagnosis or fraud detection. In the context of mobile price range predections, a high precision score would indicate that the  model is accurately predecting which mobile phones are in a certain price range, which could be useful for businesses that want to target their marketing efforts towards customers who are more likely to buy phones in a certain price range.\n",
        "\n",
        "*  **Recall**: Recall is the ratio of true positive predections to the total number of actual positive instances in the dataset. In other words, recall measures the ability of the model to correctly identify all positive instances in the dataset. A high recall score means that the model is making few false negative predictions, which is important in scenarios where false negative are costly, such as in medical diagnosis or security screening. In the context of mobile price range predictions, a high recall score would indicate that the model is correctly identifying all mobile phones that belong in a certain price range, which could be useful for businesses that want to make sure they are not missing out on potential customers in a certain price range.\n",
        "\n",
        "*   **F1-score**: F1-score is the harmonic mean of percision and recall, and it provides a balanced measures of both metrics. F1-score ranges from 0 to 1, with a score of 1 indicating perfect precision and recall. In the context of mobile price range prediction, a high F1-score would indicate that the modl is performing well in both identifying mobile phones that belong in a certain price range and accurately predicting which mobile phones are in that range. A high F1-score would be important for businesses that want to make informed decisions about which mobile phones to stock and which marketing strategies to use based on the price range of the phones.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EMyJW0J13HsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model - 3"
      ],
      "metadata": {
        "id": "pqsc5dUy3r9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "1Qg_uL8NYmFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "UpFWjPtI3vGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Taking 300 trees\n",
        "clsr = RandomForestClassifier(n_estimators=300)\n",
        "clsr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "4hjI50qpY-jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clsr.predict(x_test)\n",
        "test_score = accuracy_score(y_test, y_pred)\n",
        "test_score"
      ],
      "metadata": {
        "id": "XQ_l2OUIZN0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = clsr.predict(x_train)\n",
        "train_score = accuracy_score(y_train, y_pred_train)\n",
        "train_score"
      ],
      "metadata": {
        "id": "_vZeNYznZeAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for Test set\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "QAeA_tHnZtR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values');\n",
        "ax.set_ylabel('\\nActual Values');\n",
        "\n",
        "# Ticket Labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Display the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9uNwdme7Z3mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURED STORED"
      ],
      "metadata": {
        "id": "d8OLkhLIa7KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':x.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "NvaNMnMda_Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SyLS8R8jbcKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "The ML Model used in Random Forest for classification. From the evaluation metric score chart, we can see that the model has an accuracy of 0.80, which means that 80% of the predictions made by the model are correct. The precision for class 0 is 0.92, which means that out of all the positive predictions made for class -, 92% of them are actually corect. The recall for class 1 is 0.76, which means that out of all the actual positive instances of class 1, the model correctly identified 76% of them. The F1-score for class 2 is 0.68, which is the harmonic mean of precision and recall, and provides an overall measure of the model's accuracy for that class.\n",
        "\n",
        "In summary, the Random Forest model has moderate performance on this classification task, with accuracy precision, recall and F1-score ranging from 0.63 to 0,92 depending on the class being predicted."
      ],
      "metadata": {
        "id": "gEh7hGgtbyNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "OTk0dCXzdGm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e, GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'n_estimators':[10,50,100,200],\n",
        "          'max_depth':[10,20,30,40],\n",
        "          'min_samples_split':[2,4,6],\n",
        "          'max_features':['sqrt',4,'log2','auto'],\n",
        "          'max_leaf_nodes':[10,20,40],\n",
        "          }\n",
        "rf = RandomForestClassifier()\n",
        "clsr = GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "clsr.fit(x, y)"
      ],
      "metadata": {
        "id": "z4Ywln54dMxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_params_"
      ],
      "metadata": {
        "id": "nkYkL9KMen7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_estimator_"
      ],
      "metadata": {
        "id": "amTr9IaWeq8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_score_"
      ],
      "metadata": {
        "id": "J9DzU0-VevGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values');\n",
        "ax.set_ylabel('\\nActual Values');\n",
        "\n",
        "# Ticket Labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Display the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ox_YnIkFe2kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "clsr = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                              criterion='gini', max_depth=30, max_features='log2',\n",
        "                              max_leaf_nodes=40, max_samples=None,\n",
        "                              min_impurity_decrease=0.0,\n",
        "                              min_samples_leaf=1, min_samples_split=4,\n",
        "                              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                              n_jobs=None, oob_score=False, random_state=None,\n",
        "                              verbose=0, warm_start=False)\n",
        "clsr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "CSfYbrYwfaKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy score for Training set\n",
        "y_pred = clsr.predict(x_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "metadata": {
        "id": "zYzrqB6PgnMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "WsrNTXGKgxwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy score for Test set\n",
        "y_pred = clsr.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "IUOzPeg9g6dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Zb96iIwIhB6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURES STORED"
      ],
      "metadata": {
        "id": "Q32G7oqPhL5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':x.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "DYLSS5ExhVOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1aR1aK1che4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Which hyperparameter optimization technique have you used and why?\n",
        "\n",
        "I have used GridSearchCV hyperparameter optimization technique. GridSearchCV is a commonly used technique for hyperparameter tuning. It performs an exhaustive search over specified hyperparameter values for an estimator and ecvaluates each combination using cross-validation. GridSearchCV helps to automate the process of parameter tunig and helps to find the best combination of hyperparameters for the model, which in turn can improve its performance."
      ],
      "metadata": {
        "id": "ptNGnL_HhnVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Have you seen any improvement? Note doem the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "Yes, there is an improvement in the overall performance of the model. The accuracy has increased from 0.80 to 0.81. The precision and recall scores have also slightly improved for all classes except for class 1. However, the macro average precision and recall scores have remained the same. Overall, the model has shown a slight improvement in its performance."
      ],
      "metadata": {
        "id": "Rv4ektm-iZ_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Which Evaluation metrics did you consider for a positive business impact and why?\n",
        "\n",
        "Their is different evaluation matrix. The classification report shows precision, recall and F1-score for each class seperately as well as for the weighted average and the macro average. Therefore, the evaluation metrics that you can consider for a positive business imapct are:\n",
        "\n",
        "* **Weighted average of precision, recall and F1-score**: This metric takes into account the class imbalance by weighting the metrics by the number of samples in each class. In the context of mobile price range prediction, the weighted average of precision, recall and F1-Score can help you evaluate the overall performance of the model, taaking into account the importance of each class.\n",
        "\n",
        "* **MAcro average of precision, recall and F1-score**: This metric calculates the average precision, recall and F1-score across all classes, without taking into account the class imbalance. In the context of mobile price range prediction, the macro average of precision, recall and F1-score can help you evaluate the performance of the model on each class seperately and identify which classes are more difficult to predict.\n",
        "\n",
        "* **Confusion Matrix**: As mentioned before, the confusion matrix can provide valuable insights into classess are being misclassified and why."
      ],
      "metadata": {
        "id": "LCnNyIYxjHDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Which ML Model did you choose from above created models as your final prediction model and why?\n",
        "\n",
        "I have choosen logistic regression and xgboost models they predict better results than random forest regression."
      ],
      "metadata": {
        "id": "VArofxIs1VKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain the model which you hve used and the feature importance using any model explainability tool?\n",
        "\n",
        "I can explain the logistic regression and XGBoost models the probability of a binary outcome (in this case, the mobile price range) as a function of the input features. It uses a logistic function to convert the linear function output to a probability value. The logistic regression model can be interpreted as the effect of each featuresv on the probability of a mobile phone belonging of a mobile phone belonging to a certain price range.\n",
        "\n",
        "XGBoost, on the other hand, is a powerfull tree-based ensemble learning algorithm that uses a series of decision trees to make predictions. It works by iteratively adding decision trees to ensemble, where each new tree is trained to correct the errors made by the previous ones. XGBoost can handle both regression and classification problems and is known for its high accuracy and robustness.\n",
        "\n",
        "To explain the feature importance of the logistic regression and XGBoost models, we can use the SHAP (Shapely Additive exPlanations) model explainability tool. SHAAP values are a unified measure of features importance that can be used to explain the output of any machine learning model. They are based on the Shapely value from cooperative game theory and provide a way to allocate the contribution of each feature to the final prediction."
      ],
      "metadata": {
        "id": "FDT5fbzP1r3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the exploratory data analysis (EDA), we observed that the mobile phones in the dataset are divided into four different price ranges, each having a similar number of elements. Additionally, we found that approximately half of the devices ahve Bluetooth, while the other half do not. Furthermore, we noted that as the price range increases, there is a gradual increase in battery power and RAM shows continues growth from low-cost to very high-cost phones. Moreover, the costly phones tend to be lighter than the lower-priced ones.\n",
        "\n",
        "Our analysis indicates that RAM, battery power and pixel quality are the most significant factors affecting the price range of mobile phones. From our experiments, we concluded that logistic regression and XGBoost algorithms with hyperparameter tuning yeilded the best results in predicting the price range of mobile phones.\n",
        "\n",
        "In summary, the EDA revealed that the dataset consists of mobile phones grouped into four price ranges, with similar number of devices in each range and a 50-50 distribution of Bluetooth. We also observed that RAM and battry power increases with the price range nad higher-priced phones tend to be lighter. Our experiments suggests that the most important factors affecting the price range of mobile phones are RAM, battery power and pixel quality. Finally, we found that logistic regression and XGBoost algorithms, coupled with hyperparameter tuning, provide the best performance in predicting the price range of mobile phones."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}